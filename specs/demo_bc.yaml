# this is a demo file for running behavioral cloning
# please refer to the code for more parameter usage

# meta_data is passed to 'run_experiment.py'
meta_data:
  script_path: run_scripts/bc_exp_script.py # bc script
  exp_name: demo_bc # name of the experiment, used for generating names of log files
  description: this is a demo file for behavioral cloning # description, for human reading
  # srun settings
  num_workers: 3
  num_gpu_per_worker: 1 
  num_cpu_per_worker: 32
  mem_per_worker: 16gb
  partitions: p100,max12hours
  node_exclusions: gpu048,gpu024,gpu025,gpu012,gpu027
  extra_info: extra_info # used for generating names of log files, could leave blank
  
# -----------------------------------------------------------------------------
# each combination generates an experiment process
# could be used for param searching or multi-seed running
variables:
  # use <filter_percent> of trajectories with highest return
  # range: 0.0~1.0, where 1.0 for using all data
  filter_percent: [1.0] 
  seed: [0, 1, 2]
  bc_params:
    mode: ['MLE'] # MLE or MSE

# -----------------------------------------------------------------------------
# params already in 'variables' cannot duplicate in 'constants'
constants:
  expert_name: 'hopper_mr' # the list of names of dataset is in 'demos_listing.yaml'
  expert_idx: 0
  scale_env_with_demo_stats: false

  policy_net_size: 256
  policy_num_hidden_layers: 2 

  bc_params:

    num_epochs: 1001
    num_steps_per_epoch: 1000
    num_steps_between_train_calls: 1000
    max_path_length: 1000
    min_steps_before_training: 0

    eval_deterministic: true # use deterministic policy in online evaluation
    num_steps_per_eval: 10000
    
    replay_buffer_size: 3000000 # sufficient large
    no_terminal: false
    wrap_absorbing: false

    num_updates_per_train_call: 100
    lr: 0.0003
    momentum: 0.9
    batch_size: 256

    save_best: true
    save_best_starting_from_epoch: 0

    freq_saving: 20
    save_replay_buffer: false
    save_environment: false
    save_algorithm: false

  env_specs:
    env_name: 'hopper' # environment name
    # the environment name list is in rlkit/envs/envs_dict
    # you can customize environments by adding new environment info in this file
    env_kwargs: {}
    eval_env_seed: 78236 
    training_env_seed: 24495 
